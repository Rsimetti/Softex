{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RedesNeurais-CancerMama.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfcH1t2qapHyxwSbU8I+jQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profRCC/Softex/blob/master/RedesNeurais_CancerMama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCq6bWm1xSe9",
        "colab_type": "text"
      },
      "source": [
        "# **Classificação com Redes Neurais**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C1En4JCxYC9",
        "colab_type": "text"
      },
      "source": [
        "* Aprendizado supervisionado\n",
        "* Mapeamento de um vetor de atributos para um atributo de classe\n",
        "* Seja $x_i$ um conjunto de $n$ instâncias pertencentes a uma classe $c$ \n",
        "  * $x_i$ tem dimensão $d$\n",
        "  * existem $m$ classes, $c \\in {c_1,...,c_m}$\n",
        "* Aprendizagem é identificar a função $f$ tal que:\n",
        "  * $f([x_{i1},x_{i2},...,x_{id}]) = c$\n",
        "* O aprendizado em uma RNA consiste no ajuste dos pesos\n",
        "  * a minimização do erro é a função objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYfCMwPujETj",
        "colab_type": "text"
      },
      "source": [
        "## **Classificação de Câncer de Mama**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqsGkeH_jMxU",
        "colab_type": "text"
      },
      "source": [
        "* Dataset com atributos de nódulos identificados em imagens digitais de exames de mama. \n",
        "* Dados descrevem características do núcleo celular presentes na imagem e o diagnóstico associado (maligno ou benigno).\n",
        "* [Breast Cancer Wiscosing Data Set](https://https//www.kaggle.com/uciml/breast-cancer-wisconsin-data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKJSy3NcjZIt",
        "colab_type": "text"
      },
      "source": [
        "**Montando ambiente no Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoWPC2LtjZtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3ba2321-90f1-45b6-b4d9-397f3cc6024e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHG3vVurjkJa",
        "colab_type": "text"
      },
      "source": [
        "## 1. Importar bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G817gEAqjlUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importando bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP4MRH6_jx2M",
        "colab_type": "text"
      },
      "source": [
        "## 2. Lendo dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVcETU34jw8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "cd183954-440a-401b-f2ac-63a971e50fe7"
      },
      "source": [
        "# lendo csv e armazenando em um dataframe\n",
        "dados = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Softex/Semana3/datasets/cancer/breast_cancer.csv')\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842302         M  ...          0.4601                  0.11890\n",
              "1    842517         M  ...          0.2750                  0.08902\n",
              "2  84300903         M  ...          0.3613                  0.08758\n",
              "3  84348301         M  ...          0.6638                  0.17300\n",
              "4  84358402         M  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSHMB0-bj_d3",
        "colab_type": "text"
      },
      "source": [
        "## 3. Limpeza e organização dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oJ-zPRCj9lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#verificar se existem valores NAN, ? ou dados faltantes\n",
        "dados = dados.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJc8fDFijv2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "3ecc7957-a6fa-4890-8746-5eff590d96ab"
      },
      "source": [
        "#excluir colunas irrelevantes\n",
        "dados = dados.drop(columns=['id'])\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0         M        17.99  ...          0.4601                  0.11890\n",
              "1         M        20.57  ...          0.2750                  0.08902\n",
              "2         M        19.69  ...          0.3613                  0.08758\n",
              "3         M        11.42  ...          0.6638                  0.17300\n",
              "4         M        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cZ54LNMkFl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ff52a3b6-8919-411d-fe12-f57575efa0f8"
      },
      "source": [
        "#trocando o tipo do atributo diagnostico por um tipo numerico\n",
        "dados['diagnosis'] = dados['diagnosis'].replace(['M','B'],[1,0])\n",
        "dados.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0          1        17.99  ...          0.4601                  0.11890\n",
              "1          1        20.57  ...          0.2750                  0.08902\n",
              "2          1        19.69  ...          0.3613                  0.08758\n",
              "3          1        11.42  ...          0.6638                  0.17300\n",
              "4          1        20.29  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bXkHRdvoszV",
        "colab_type": "text"
      },
      "source": [
        "## 4. Re-escala dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS1lnfH1pFJU",
        "colab_type": "text"
      },
      "source": [
        "### Re-escala usando máximo e mínimo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TLtT7QUo3r9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dados = (dados - dados.min())/(dados.max()-dados.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJJnoasZkFTe",
        "colab_type": "text"
      },
      "source": [
        "## 5. Organizando dados para modelagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KyZqkJ5mnY3",
        "colab_type": "text"
      },
      "source": [
        "### Dividir os dados em atributos descritores e atributo de classe (target)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Q09IX2lzeC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "cbef173b-a8c7-437a-b0a7-cbc8c14f0c6d"
      },
      "source": [
        "#dividindo dados em atributos descritores e atributo de classe\n",
        "X = dados.iloc[:,1:]\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.521037</td>\n",
              "      <td>0.022658</td>\n",
              "      <td>0.545989</td>\n",
              "      <td>0.363733</td>\n",
              "      <td>0.593753</td>\n",
              "      <td>0.792037</td>\n",
              "      <td>0.703140</td>\n",
              "      <td>0.731113</td>\n",
              "      <td>0.686364</td>\n",
              "      <td>0.605518</td>\n",
              "      <td>0.356147</td>\n",
              "      <td>0.120469</td>\n",
              "      <td>0.369034</td>\n",
              "      <td>0.273811</td>\n",
              "      <td>0.159296</td>\n",
              "      <td>0.351398</td>\n",
              "      <td>0.135682</td>\n",
              "      <td>0.300625</td>\n",
              "      <td>0.311645</td>\n",
              "      <td>0.183042</td>\n",
              "      <td>0.620776</td>\n",
              "      <td>0.141525</td>\n",
              "      <td>0.668310</td>\n",
              "      <td>0.450698</td>\n",
              "      <td>0.601136</td>\n",
              "      <td>0.619292</td>\n",
              "      <td>0.568610</td>\n",
              "      <td>0.912027</td>\n",
              "      <td>0.598462</td>\n",
              "      <td>0.418864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.643144</td>\n",
              "      <td>0.272574</td>\n",
              "      <td>0.615783</td>\n",
              "      <td>0.501591</td>\n",
              "      <td>0.289880</td>\n",
              "      <td>0.181768</td>\n",
              "      <td>0.203608</td>\n",
              "      <td>0.348757</td>\n",
              "      <td>0.379798</td>\n",
              "      <td>0.141323</td>\n",
              "      <td>0.156437</td>\n",
              "      <td>0.082589</td>\n",
              "      <td>0.124440</td>\n",
              "      <td>0.125660</td>\n",
              "      <td>0.119387</td>\n",
              "      <td>0.081323</td>\n",
              "      <td>0.046970</td>\n",
              "      <td>0.253836</td>\n",
              "      <td>0.084539</td>\n",
              "      <td>0.091110</td>\n",
              "      <td>0.606901</td>\n",
              "      <td>0.303571</td>\n",
              "      <td>0.539818</td>\n",
              "      <td>0.435214</td>\n",
              "      <td>0.347553</td>\n",
              "      <td>0.154563</td>\n",
              "      <td>0.192971</td>\n",
              "      <td>0.639175</td>\n",
              "      <td>0.233590</td>\n",
              "      <td>0.222878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.601496</td>\n",
              "      <td>0.390260</td>\n",
              "      <td>0.595743</td>\n",
              "      <td>0.449417</td>\n",
              "      <td>0.514309</td>\n",
              "      <td>0.431017</td>\n",
              "      <td>0.462512</td>\n",
              "      <td>0.635686</td>\n",
              "      <td>0.509596</td>\n",
              "      <td>0.211247</td>\n",
              "      <td>0.229622</td>\n",
              "      <td>0.094303</td>\n",
              "      <td>0.180370</td>\n",
              "      <td>0.162922</td>\n",
              "      <td>0.150831</td>\n",
              "      <td>0.283955</td>\n",
              "      <td>0.096768</td>\n",
              "      <td>0.389847</td>\n",
              "      <td>0.205690</td>\n",
              "      <td>0.127006</td>\n",
              "      <td>0.556386</td>\n",
              "      <td>0.360075</td>\n",
              "      <td>0.508442</td>\n",
              "      <td>0.374508</td>\n",
              "      <td>0.483590</td>\n",
              "      <td>0.385375</td>\n",
              "      <td>0.359744</td>\n",
              "      <td>0.835052</td>\n",
              "      <td>0.403706</td>\n",
              "      <td>0.213433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.210090</td>\n",
              "      <td>0.360839</td>\n",
              "      <td>0.233501</td>\n",
              "      <td>0.102906</td>\n",
              "      <td>0.811321</td>\n",
              "      <td>0.811361</td>\n",
              "      <td>0.565604</td>\n",
              "      <td>0.522863</td>\n",
              "      <td>0.776263</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.139091</td>\n",
              "      <td>0.175875</td>\n",
              "      <td>0.126655</td>\n",
              "      <td>0.038155</td>\n",
              "      <td>0.251453</td>\n",
              "      <td>0.543215</td>\n",
              "      <td>0.142955</td>\n",
              "      <td>0.353665</td>\n",
              "      <td>0.728148</td>\n",
              "      <td>0.287205</td>\n",
              "      <td>0.248310</td>\n",
              "      <td>0.385928</td>\n",
              "      <td>0.241347</td>\n",
              "      <td>0.094008</td>\n",
              "      <td>0.915472</td>\n",
              "      <td>0.814012</td>\n",
              "      <td>0.548642</td>\n",
              "      <td>0.884880</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.773711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.629893</td>\n",
              "      <td>0.156578</td>\n",
              "      <td>0.630986</td>\n",
              "      <td>0.489290</td>\n",
              "      <td>0.430351</td>\n",
              "      <td>0.347893</td>\n",
              "      <td>0.463918</td>\n",
              "      <td>0.518390</td>\n",
              "      <td>0.378283</td>\n",
              "      <td>0.186816</td>\n",
              "      <td>0.233822</td>\n",
              "      <td>0.093065</td>\n",
              "      <td>0.220563</td>\n",
              "      <td>0.163688</td>\n",
              "      <td>0.332359</td>\n",
              "      <td>0.167918</td>\n",
              "      <td>0.143636</td>\n",
              "      <td>0.357075</td>\n",
              "      <td>0.136179</td>\n",
              "      <td>0.145800</td>\n",
              "      <td>0.519744</td>\n",
              "      <td>0.123934</td>\n",
              "      <td>0.506948</td>\n",
              "      <td>0.341575</td>\n",
              "      <td>0.437364</td>\n",
              "      <td>0.172415</td>\n",
              "      <td>0.319489</td>\n",
              "      <td>0.558419</td>\n",
              "      <td>0.157500</td>\n",
              "      <td>0.142595</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0     0.521037      0.022658  ...        0.598462                 0.418864\n",
              "1     0.643144      0.272574  ...        0.233590                 0.222878\n",
              "2     0.601496      0.390260  ...        0.403706                 0.213433\n",
              "3     0.210090      0.360839  ...        1.000000                 0.773711\n",
              "4     0.629893      0.156578  ...        0.157500                 0.142595\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTIdaPzPmJLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "95c07c81-1f9e-426e-facc-e50c17308bde"
      },
      "source": [
        "y = dados.diagnosis\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    1.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    1.0\n",
              "Name: diagnosis, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwGz4qFCmsen",
        "colab_type": "text"
      },
      "source": [
        "### Dividir os dados em treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GinSY_tTlZTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUDHN6phzv6g",
        "colab_type": "text"
      },
      "source": [
        "* Divide a matriz em subconjuntos aleatórios de treino e teste\n",
        "* test_size: tamanho do subconjunto de teste (em percentual)\n",
        "* random_state: define a semente para a aleatoriedade (se não definido, semente aleatória)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TY7h0UllqpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)#random_state=42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFW7YP_xpT8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "d06a06b0-517e-4fa0-aa98-301d7e2f26c9"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>0.150930</td>\n",
              "      <td>0.174839</td>\n",
              "      <td>0.143459</td>\n",
              "      <td>0.071432</td>\n",
              "      <td>0.548614</td>\n",
              "      <td>0.187811</td>\n",
              "      <td>0.025398</td>\n",
              "      <td>0.064115</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.413648</td>\n",
              "      <td>0.146406</td>\n",
              "      <td>0.238861</td>\n",
              "      <td>0.120388</td>\n",
              "      <td>0.051958</td>\n",
              "      <td>0.197199</td>\n",
              "      <td>0.065626</td>\n",
              "      <td>0.019356</td>\n",
              "      <td>0.155200</td>\n",
              "      <td>0.477683</td>\n",
              "      <td>0.174751</td>\n",
              "      <td>0.109925</td>\n",
              "      <td>0.144723</td>\n",
              "      <td>0.096867</td>\n",
              "      <td>0.045075</td>\n",
              "      <td>0.371987</td>\n",
              "      <td>0.069244</td>\n",
              "      <td>0.017316</td>\n",
              "      <td>0.088625</td>\n",
              "      <td>0.392667</td>\n",
              "      <td>0.165027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.119409</td>\n",
              "      <td>0.092323</td>\n",
              "      <td>0.114367</td>\n",
              "      <td>0.055313</td>\n",
              "      <td>0.449309</td>\n",
              "      <td>0.139685</td>\n",
              "      <td>0.069260</td>\n",
              "      <td>0.103181</td>\n",
              "      <td>0.381313</td>\n",
              "      <td>0.402064</td>\n",
              "      <td>0.060040</td>\n",
              "      <td>0.136271</td>\n",
              "      <td>0.054281</td>\n",
              "      <td>0.016619</td>\n",
              "      <td>0.268314</td>\n",
              "      <td>0.090636</td>\n",
              "      <td>0.050126</td>\n",
              "      <td>0.269180</td>\n",
              "      <td>0.174312</td>\n",
              "      <td>0.071625</td>\n",
              "      <td>0.081821</td>\n",
              "      <td>0.097015</td>\n",
              "      <td>0.073310</td>\n",
              "      <td>0.031877</td>\n",
              "      <td>0.404345</td>\n",
              "      <td>0.084903</td>\n",
              "      <td>0.070823</td>\n",
              "      <td>0.213986</td>\n",
              "      <td>0.174453</td>\n",
              "      <td>0.148826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>0.249373</td>\n",
              "      <td>0.430504</td>\n",
              "      <td>0.237648</td>\n",
              "      <td>0.137010</td>\n",
              "      <td>0.264422</td>\n",
              "      <td>0.100055</td>\n",
              "      <td>0.040159</td>\n",
              "      <td>0.062674</td>\n",
              "      <td>0.244444</td>\n",
              "      <td>0.206403</td>\n",
              "      <td>0.040703</td>\n",
              "      <td>0.172118</td>\n",
              "      <td>0.038637</td>\n",
              "      <td>0.020990</td>\n",
              "      <td>0.115002</td>\n",
              "      <td>0.073587</td>\n",
              "      <td>0.023763</td>\n",
              "      <td>0.086210</td>\n",
              "      <td>0.115354</td>\n",
              "      <td>0.051967</td>\n",
              "      <td>0.221985</td>\n",
              "      <td>0.532249</td>\n",
              "      <td>0.210817</td>\n",
              "      <td>0.107575</td>\n",
              "      <td>0.359440</td>\n",
              "      <td>0.148548</td>\n",
              "      <td>0.098243</td>\n",
              "      <td>0.217698</td>\n",
              "      <td>0.302582</td>\n",
              "      <td>0.177030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.581618</td>\n",
              "      <td>0.566791</td>\n",
              "      <td>0.581231</td>\n",
              "      <td>0.432025</td>\n",
              "      <td>0.373567</td>\n",
              "      <td>0.467824</td>\n",
              "      <td>0.388238</td>\n",
              "      <td>0.377386</td>\n",
              "      <td>0.400505</td>\n",
              "      <td>0.266428</td>\n",
              "      <td>0.160891</td>\n",
              "      <td>0.054367</td>\n",
              "      <td>0.130566</td>\n",
              "      <td>0.114621</td>\n",
              "      <td>0.112248</td>\n",
              "      <td>0.232283</td>\n",
              "      <td>0.088308</td>\n",
              "      <td>0.182667</td>\n",
              "      <td>0.106208</td>\n",
              "      <td>0.103686</td>\n",
              "      <td>0.577019</td>\n",
              "      <td>0.503198</td>\n",
              "      <td>0.552767</td>\n",
              "      <td>0.400069</td>\n",
              "      <td>0.526514</td>\n",
              "      <td>0.612888</td>\n",
              "      <td>0.486502</td>\n",
              "      <td>0.613402</td>\n",
              "      <td>0.415336</td>\n",
              "      <td>0.375574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>0.221922</td>\n",
              "      <td>0.348664</td>\n",
              "      <td>0.217124</td>\n",
              "      <td>0.115673</td>\n",
              "      <td>0.442087</td>\n",
              "      <td>0.230507</td>\n",
              "      <td>0.098407</td>\n",
              "      <td>0.107207</td>\n",
              "      <td>0.403535</td>\n",
              "      <td>0.308551</td>\n",
              "      <td>0.034474</td>\n",
              "      <td>0.113662</td>\n",
              "      <td>0.029967</td>\n",
              "      <td>0.015947</td>\n",
              "      <td>0.120271</td>\n",
              "      <td>0.112792</td>\n",
              "      <td>0.046465</td>\n",
              "      <td>0.100360</td>\n",
              "      <td>0.092981</td>\n",
              "      <td>0.061364</td>\n",
              "      <td>0.192814</td>\n",
              "      <td>0.447495</td>\n",
              "      <td>0.182230</td>\n",
              "      <td>0.089805</td>\n",
              "      <td>0.553589</td>\n",
              "      <td>0.261092</td>\n",
              "      <td>0.220288</td>\n",
              "      <td>0.279038</td>\n",
              "      <td>0.323477</td>\n",
              "      <td>0.226026</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "60      0.150930      0.174839  ...        0.392667                 0.165027\n",
              "21      0.119409      0.092323  ...        0.174453                 0.148826\n",
              "490     0.249373      0.430504  ...        0.302582                 0.177030\n",
              "33      0.581618      0.566791  ...        0.415336                 0.375574\n",
              "531     0.221922      0.348664  ...        0.323477                 0.226026\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ8riK2Im2Ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3fa64d9f-d568-4efa-db15-5ce5a5a13a50"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60     0.0\n",
              "21     0.0\n",
              "490    0.0\n",
              "33     1.0\n",
              "531    0.0\n",
              "Name: diagnosis, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4ns1Hc-nqCq",
        "colab_type": "text"
      },
      "source": [
        "## 5. Definindo algoritmo de aprendizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOGTYHCqNlza",
        "colab_type": "text"
      },
      "source": [
        "Rede Neural Multi-Layer Perceptron (MLP)\n",
        "\n",
        "Parâmetros da MLP:\n",
        "* Número de neurônios e camadas - hidden_layer_sizes\n",
        "  * tupla com a arquitetura\n",
        "  * ex: (100,10) - duas camadas escondidas com 100 e 10 neurônios respectivamente\n",
        "  * ex: (100,50,10)\n",
        "* Função de ativação - activation\n",
        "  * função de ativação das camadas escondidas\n",
        "  * identidade - identity\n",
        "  * sigmóide logística - logistic\n",
        "  * tangente hiperbólica - tanh\n",
        "  * função de unidade linear retificada - relu (max(0,x))\n",
        "* Treinamento - solver\n",
        "  * forma de otimizar os pesos da rede\n",
        "  * gradiente estocástico  proposto por Kingma, Diederik, and Jimmy Ba - adam\n",
        "  * descida do gradiente estocástico - sgd\n",
        "  * familia dos métodos quasi-Newton - lbfgs\n",
        "* Taxa de aprendizado - learning_rate\n",
        "  * taxa constant - constant\n",
        "  * decrescente - invscaling\n",
        "  * adaptativa - adaptive\n",
        "* Número máximo de iterações - max_iter\n",
        "  * número de épocas de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R060QCRyle3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iujA_MQCnvS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#definindo modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKPsspvNnvcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "68dee8f5-0f48-47d5-d2cc-64b0d647fc1b"
      },
      "source": [
        "#treinando modelo\n",
        "classificador.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oznlyR7Qn_L6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "afa8a915-999f-4684-c868-d0fe4a9dc0a1"
      },
      "source": [
        "#realizando classificação\n",
        "classificacao = classificador.predict(X_test)\n",
        "classificacao"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV76fkrNpkco",
        "colab_type": "text"
      },
      "source": [
        "## 6. Avaliação do classificador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGRlWyKB64_t",
        "colab_type": "text"
      },
      "source": [
        "Acurácia\n",
        "* taxa de acertos do classificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa4TCBSpqwnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando acurácia\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_FGS639rCIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f7b8ecc7-d434-4b45-8fc4-ff98b1d375b6"
      },
      "source": [
        "acuracia = accuracy_score(y_test,classificacao)\n",
        "round(acuracia,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vLDKXqY7DUY",
        "colab_type": "text"
      },
      "source": [
        "Precisão\n",
        "* taxa de instâncias classificadas como positivas que são realmente positivas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggPj1BYXrx6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando precisão\n",
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoxjHujErvbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f14d775-a33f-44eb-9729-7c0c784ec79f"
      },
      "source": [
        "precisao = precision_score(y_test,classificacao)\n",
        "round(precisao,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpcDfq5_7Lra",
        "colab_type": "text"
      },
      "source": [
        "Recall\n",
        "* taxa de instâncias positivas classificadas corretamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_M8ppDZr-RM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando recall (revocação)\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSfgW_nTsZfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1cd833c7-b90e-4784-cc47-37a0ed0b71b6"
      },
      "source": [
        "recall = recall_score(y_test,classificacao)\n",
        "round(recall,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XWUh-lR7erI",
        "colab_type": "text"
      },
      "source": [
        "F1-score\n",
        "* balanço entre precisão e recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yylhPvmNrN5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando f1-score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "188ZXPCVrU2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c003a666-cc36-49d5-ae6b-b7ad2ab776ac"
      },
      "source": [
        "f1 = f1_score(y_test,classificacao)\n",
        "round(f1,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6nyOv61QIhi",
        "colab_type": "text"
      },
      "source": [
        "### Curva ROC\n",
        "* Representação gráfica do desempenho de um classificador binário\n",
        "* Razão entre a taxa de positivos verdadeiros (TPR) e positivos falsos (FPR)\n",
        "* Interpretação\n",
        "  * quanto maior tpr, melhor\n",
        "  * quanto menor fpr, melhor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pTLq8z7tDSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotando curva roc\n",
        "from sklearn.metrics import roc_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnnXV20ZtGQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr, tpr, _ = roc_curve(y_test,classificacao)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeQIx4BOuoEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5f1613b9-bb92-4368-cebd-7a425aba47b6"
      },
      "source": [
        "plt.plot(fpr,tpr,marker='.')\n",
        "plt.title('Curva ROC')\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiro Positivos')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp37m0UZVS54",
        "colab_type": "text"
      },
      "source": [
        "## Área sob a curva (*Area under the curve - AUC)*\n",
        "* Área sob a curva ROC\n",
        "* Interpretação numérica da curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0am_-JunvJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando area sob a curva ROC\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruvJsxKSs1r2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20a63598-051c-42f9-8ecb-515aa5f6e9a3"
      },
      "source": [
        "auc = roc_auc_score(y_test,classificacao)\n",
        "round(auc,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0f6-FrrveF-",
        "colab_type": "text"
      },
      "source": [
        "## Validação cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMyRfcDBbjX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# avaliando modelo com cross validation\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVW_YaJsb3Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e_q9hjyb7Qk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8a7893b6-dd6c-4039-db48-4793eaadb283"
      },
      "source": [
        "#calculando os scores\n",
        "scores = cross_val_score(classificador,X,y,cv=10)\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.96491228, 0.98245614, 0.94736842, 1.        ,\n",
              "       0.98245614, 0.94736842, 1.        , 1.        , 0.98214286])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6_Pq7H-dZ8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4649f98f-d10c-420a-9e0b-9b95f5e435b1"
      },
      "source": [
        "round(scores.mean(),3),round(scores.std(),3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.981, 0.02)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WplzueKkgShb",
        "colab_type": "text"
      },
      "source": [
        "## 7. Comparando MLP com Árvore de Decisão e Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckSgPwibm0ZJ",
        "colab_type": "text"
      },
      "source": [
        "### Validação Cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMEFP0hC-1GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXee7pyqlRgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando árvore\n",
        "arvore = DecisionTreeClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_arvore = cross_val_score(arvore,X,y,cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cmIOXL2mnWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando random forest\n",
        "floresta = RandomForestClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_floresta = cross_val_score(floresta,X,y,cv=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWYYR_a0_Tmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando rede neural\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)\n",
        "\n",
        "#calculando os scores\n",
        "scores_mlp = cross_val_score(mlp,X,y,cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBJPMlq0_AfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f8616a0c-11c9-40c7-f982-dee864447b14"
      },
      "source": [
        "print('Árvore de Decisão: ', round(scores_arvore.mean(),3),round(scores_arvore.std(),3))\n",
        "print('Random Forest: ', round(scores.mean(),3),round(scores.std(),3))\n",
        "print('MLP:', round(scores_mlp.mean(),3),round(scores_mlp.std(),3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão:  0.916 0.039\n",
            "Random Forest:  0.981 0.02\n",
            "MLP: 0.979 0.019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tydxDGEQADcv",
        "colab_type": "text"
      },
      "source": [
        "## 8. Otimização de Parâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-DT4pI-QdE8",
        "colab_type": "text"
      },
      "source": [
        "## Otimizando parâmetros\n",
        "* Problema \n",
        "  * qual a melhor configuração de parâmetros para o modelo\n",
        "* Otimização\n",
        "  * escolher o melhor elemento de um conjunto\n",
        "  * o significado de melhor é dado por uma função objetivo\n",
        "    * taxa de erro\n",
        "\n",
        "  <img src=https://www.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/ac3f2f5a-9199-4bb7-8ce6-47e4dc307a0e.png width=500>\n",
        "\n",
        "* Solução \"mais simples\"\n",
        "  * tente todas as possibilidades\n",
        "  * alto custo computacional\n",
        "* Solução heurística\n",
        "  * otimização estocástica\n",
        "  * busca no espaço de soluções\n",
        "* Random search\n",
        "  * busca aleatória\n",
        "  * sorteia alguns pontos do espaço e escolhe o melhor\n",
        "\n",
        "  <img src= https://maelfabien.github.io/assets/images/expl4_4.jpg width=500>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79btaYUOXLxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaSShhRZXr3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = [\n",
        "              {\n",
        "                  'hidden_layer_sizes': [(10),(50),(100),(50,10),(100,50)],\n",
        "                  'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "                  'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "                  'max_iter': [500,1000,2000]\n",
        "              }\n",
        "              \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA4bxw1tXvrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = RandomizedSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRiHGToCYYZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "26389e64-6811-4adc-9252-5426bf6e69c9"
      },
      "source": [
        "mlp.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           random...\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions=[{'activation': ['identity', 'logistic',\n",
              "                                                        'tanh', 'relu'],\n",
              "                                         'hidden_layer_sizes': [10, 50, 100,\n",
              "                                                                (50, 10),\n",
              "                                                                (100, 50)],\n",
              "                                         'max_iter': [500, 1000, 2000],\n",
              "                                         'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdDA2KzeYiuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb6de16c-18d4-4033-de08-129437b6bd22"
      },
      "source": [
        "print(mlp.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'solver': 'adam', 'max_iter': 500, 'hidden_layer_sizes': 50, 'activation': 'logistic'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64WPH3_MYk9M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b8df265-2cb2-4354-9e6c-b49d5aa89538"
      },
      "source": [
        "print(round(mlp.best_score_,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtW_rjA5XDWY",
        "colab_type": "text"
      },
      "source": [
        "* Grid search\n",
        "  * monta um espaço de soluções reduzido como um reticulado\n",
        "  * testa todas as soluções, guardando a melhor\n",
        "\n",
        "  <img src=https://maelfabien.github.io/assets/images/expl4_1.jpg width=500>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJL5uB1DALE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDIHaQUJQvTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = GridSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se6zKMahRGlC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "399c5c9b-13d6-4505-885b-496a656b0fa4"
      },
      "source": [
        "mlp.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=1000, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_stat...\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'activation': ['identity', 'logistic', 'tanh',\n",
              "                                         'relu'],\n",
              "                          'hidden_layer_sizes': [10, 50, 100, (50, 10),\n",
              "                                                 (100, 50)],\n",
              "                          'max_iter': [500, 1000, 2000],\n",
              "                          'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubTD44m7RulT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b837324-80ef-45a5-96d4-472c76e21f71"
      },
      "source": [
        "print(mlp.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': 'identity', 'hidden_layer_sizes': 10, 'max_iter': 2000, 'solver': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dQUl07HXdli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66a44bd7-fe65-482e-80a2-ffdcb8ddd613"
      },
      "source": [
        "print(mlp.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9807017543859651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZXQ2y1lW3zO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61d02fa2-5451-4764-fb22-139757d1ae4f"
      },
      "source": [
        "mlp.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.10085878, 0.37293754, 0.39574351, 0.13594613, 0.69761062,\n",
              "        0.56198049, 0.13781214, 0.68671989, 0.66646929, 0.2320087 ,\n",
              "        0.7469069 , 0.85803967, 0.37283807, 1.333077  , 0.87133412,\n",
              "        0.4855773 , 1.31437697, 0.84062619, 0.30150728, 0.96937237,\n",
              "        0.93753738, 0.26690264, 1.64909024, 0.92895794, 0.27882524,\n",
              "        1.64822073, 0.92602906, 0.29086843, 0.92397113, 0.6331284 ,\n",
              "        0.45072312, 1.25837474, 0.56350913, 0.42188411, 1.27538438,\n",
              "        0.60727224, 0.75724292, 1.51951556, 0.60602579, 0.88707767,\n",
              "        2.02117114, 0.62106037, 0.97087469, 2.06210942, 0.60815554,\n",
              "        0.0753191 , 0.13420448, 0.50418062, 0.07081823, 0.26108141,\n",
              "        0.96388631, 0.04194746, 0.39289618, 1.00863819, 0.2178802 ,\n",
              "        0.93975182, 1.28080096, 0.20079527, 1.87363224, 1.91458793,\n",
              "        0.23150311, 4.61284986, 1.70033846, 0.48186321, 1.79894366,\n",
              "        1.89381175, 0.38977385, 3.54224715, 2.39680157, 0.43762217,\n",
              "        7.06554484, 2.30587707, 0.59877915, 0.1556119 , 1.61019688,\n",
              "        0.54079862, 0.1623786 , 1.85165386, 0.43085446, 0.15489688,\n",
              "        1.93532863, 1.36708407, 0.1569273 , 2.53202953, 1.12449522,\n",
              "        0.15978003, 2.50660987, 1.01932578, 0.17301474, 2.23001533,\n",
              "        0.06173859, 0.45262012, 0.52050662, 0.05544147, 0.89655046,\n",
              "        0.74502754, 0.04564605, 0.9164197 , 0.74245944, 0.16166115,\n",
              "        1.24299645, 1.35117764, 0.15489907, 2.23531508, 1.35987787,\n",
              "        0.16051993, 2.22975912, 1.42488971, 0.32924829, 1.89608321,\n",
              "        1.66318407, 0.3043005 , 3.40890002, 1.79071946, 0.35257936,\n",
              "        3.33809805, 1.80114107, 0.37404304, 1.53761015, 1.17356925,\n",
              "        0.23791342, 2.35879755, 1.13320775, 0.28069663, 2.29096456,\n",
              "        1.05259099, 0.53143139, 3.00520949, 1.35109563, 0.5238133 ,\n",
              "        4.28237872, 1.20081811, 0.51531439, 4.17742991, 1.19192476,\n",
              "        0.07274294, 0.47933455, 0.53822484, 0.07903028, 0.93616915,\n",
              "        0.76708579, 0.05831623, 1.06683083, 0.74558311, 0.10617285,\n",
              "        1.02937875, 1.12419853, 0.13400922, 1.99658947, 1.15826159,\n",
              "        0.12242036, 1.93643556, 1.15062985, 0.21259303, 1.40005131,\n",
              "        1.39843745, 0.19161425, 2.5971777 , 1.51538453, 0.19054012,\n",
              "        2.61416016, 1.57015233, 0.14508224, 1.30855565, 1.10353398,\n",
              "        0.16445646, 2.3009522 , 1.3696919 , 0.1862359 , 2.32963185,\n",
              "        1.18326812, 0.40206032, 2.23299646, 1.49313064, 0.42789307,\n",
              "        3.46458483, 1.09111362, 0.33356695, 3.65116143, 1.34969997]),\n",
              " 'mean_score_time': array([0.00135527, 0.00180655, 0.00198264, 0.00134702, 0.00126143,\n",
              "        0.00171328, 0.00125098, 0.00125713, 0.00127821, 0.0016479 ,\n",
              "        0.00196304, 0.00206728, 0.00168939, 0.00173101, 0.00170112,\n",
              "        0.00167708, 0.00170064, 0.00169659, 0.00174003, 0.00186758,\n",
              "        0.00171785, 0.00171342, 0.00171971, 0.00219893, 0.00172853,\n",
              "        0.00172925, 0.00175972, 0.00172853, 0.00171056, 0.00177875,\n",
              "        0.00172634, 0.00199866, 0.0016901 , 0.00174861, 0.00175962,\n",
              "        0.00172286, 0.00182471, 0.0017909 , 0.00180702, 0.00189395,\n",
              "        0.00181766, 0.0018034 , 0.00182562, 0.00181837, 0.00188837,\n",
              "        0.00145984, 0.00134768, 0.0018085 , 0.00132451, 0.00137987,\n",
              "        0.00165434, 0.00140176, 0.0013586 , 0.00126338, 0.00186605,\n",
              "        0.00183797, 0.00207105, 0.00187554, 0.00186191, 0.00190463,\n",
              "        0.00189548, 0.00188012, 0.00185394, 0.00207586, 0.0020525 ,\n",
              "        0.00207715, 0.00209289, 0.00204301, 0.00210323, 0.00329375,\n",
              "        0.00207119, 0.00214267, 0.00195937, 0.00193992, 0.00193381,\n",
              "        0.00195785, 0.00192804, 0.00194397, 0.00193572, 0.00198708,\n",
              "        0.00197601, 0.00236802, 0.00244699, 0.00234156, 0.00240831,\n",
              "        0.00241261, 0.00239048, 0.00238066, 0.00240846, 0.00263271,\n",
              "        0.00146527, 0.0018219 , 0.00194511, 0.00130191, 0.00177088,\n",
              "        0.0012907 , 0.00128884, 0.00133824, 0.00130682, 0.00195818,\n",
              "        0.00212507, 0.00201502, 0.00195355, 0.00188198, 0.00191445,\n",
              "        0.00197787, 0.00194759, 0.00188966, 0.00225277, 0.00251665,\n",
              "        0.00214052, 0.00423403, 0.00214524, 0.00214047, 0.00232406,\n",
              "        0.00215755, 0.00213618, 0.00204782, 0.00213447, 0.00200539,\n",
              "        0.00203924, 0.00200448, 0.00205607, 0.00203981, 0.00203342,\n",
              "        0.00202322, 0.00279303, 0.00273976, 0.00251255, 0.00271335,\n",
              "        0.00255127, 0.00249257, 0.00264611, 0.0024621 , 0.00251064,\n",
              "        0.00135655, 0.00185437, 0.00196652, 0.00134358, 0.00173559,\n",
              "        0.00134811, 0.00128512, 0.00127702, 0.00129237, 0.00175281,\n",
              "        0.00176492, 0.00176153, 0.00192089, 0.00174761, 0.0017509 ,\n",
              "        0.00176725, 0.00175686, 0.00173955, 0.00182314, 0.00186772,\n",
              "        0.00180554, 0.00182443, 0.00184088, 0.00181231, 0.00185118,\n",
              "        0.00183129, 0.00185285, 0.00184617, 0.00181322, 0.00186267,\n",
              "        0.00188951, 0.00186715, 0.00184469, 0.001826  , 0.00183277,\n",
              "        0.00183988, 0.00199046, 0.00202508, 0.00206056, 0.00201178,\n",
              "        0.00202765, 0.00206323, 0.00199671, 0.00204959, 0.00199833]),\n",
              " 'mean_test_score': array([0.95609377, 0.93320913, 0.96314237, 0.95433939, 0.96134141,\n",
              "        0.9754386 , 0.95784816, 0.94904518, 0.98070175, 0.95433939,\n",
              "        0.94028878, 0.97719298, 0.95784816, 0.96134141, 0.9719143 ,\n",
              "        0.95079957, 0.95256948, 0.9754386 , 0.95787921, 0.94555193,\n",
              "        0.97717746, 0.95787921, 0.95607825, 0.97542307, 0.95786369,\n",
              "        0.95606272, 0.97893184, 0.95609377, 0.96134141, 0.97366868,\n",
              "        0.95256948, 0.97012886, 0.97717746, 0.95433939, 0.96662009,\n",
              "        0.97542307, 0.95083062, 0.96837448, 0.97893184, 0.95433939,\n",
              "        0.97188325, 0.97015991, 0.95784816, 0.96662009, 0.97189877,\n",
              "        0.95606272, 0.6274181 , 0.9490607 , 0.9648657 , 0.6396988 ,\n",
              "        0.96839   , 0.96657351, 0.68180407, 0.97189877, 0.95783263,\n",
              "        0.63445117, 0.97365316, 0.96137246, 0.80329141, 0.97366868,\n",
              "        0.9561093 , 0.94204316, 0.97366868, 0.96137246, 0.64146872,\n",
              "        0.97717746, 0.95960255, 0.83842571, 0.97542307, 0.9561093 ,\n",
              "        0.94205869, 0.97542307, 0.95780158, 0.6274181 , 0.97717746,\n",
              "        0.96309579, 0.6274181 , 0.97366868, 0.95427729, 0.6274181 ,\n",
              "        0.97542307, 0.95609377, 0.6274181 , 0.9719143 , 0.89819904,\n",
              "        0.6274181 , 0.9719143 , 0.96488123, 0.6274181 , 0.9719143 ,\n",
              "        0.96839   , 0.93325571, 0.9719143 , 0.96309579, 0.9438286 ,\n",
              "        0.97366868, 0.96660456, 0.95435491, 0.97366868, 0.95787921,\n",
              "        0.94028878, 0.97542307, 0.95606272, 0.95432386, 0.97015991,\n",
              "        0.96134141, 0.95607825, 0.97542307, 0.95961807, 0.94027325,\n",
              "        0.97893184, 0.9561093 , 0.95081509, 0.97893184, 0.95783263,\n",
              "        0.95607825, 0.97542307, 0.95781711, 0.96134141, 0.97542307,\n",
              "        0.95958702, 0.96839   , 0.9719143 , 0.95430834, 0.96663562,\n",
              "        0.9719143 , 0.95609377, 0.97012886, 0.97542307, 0.95783263,\n",
              "        0.96662009, 0.97542307, 0.95787921, 0.9719143 , 0.97893184,\n",
              "        0.94896755, 0.90338457, 0.97014439, 0.95960255, 0.94025772,\n",
              "        0.97540755, 0.95786369, 0.95079957, 0.97192982, 0.95783263,\n",
              "        0.93501009, 0.97893184, 0.95786369, 0.95609377, 0.97542307,\n",
              "        0.95783263, 0.95079957, 0.97719298, 0.96134141, 0.94028878,\n",
              "        0.97717746, 0.95784816, 0.95958702, 0.97542307, 0.95609377,\n",
              "        0.95958702, 0.97893184, 0.95607825, 0.95083062, 0.97717746,\n",
              "        0.95606272, 0.97189877, 0.9754386 , 0.96134141, 0.96311132,\n",
              "        0.97015991, 0.95079957, 0.95960255, 0.9719143 , 0.95786369,\n",
              "        0.96662009, 0.97894737, 0.96135693, 0.96663562, 0.97717746]),\n",
              " 'param_activation': masked_array(data=['identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_hidden_layer_sizes': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), 10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_iter': masked_array(data=[500, 500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500,\n",
              "                    500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500,\n",
              "                    500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'}],\n",
              " 'rank_test_score': array([120, 165,  77, 135,  84,  19, 106, 152,   1, 135, 159,  10, 106,\n",
              "         84,  49, 147, 142,  19,  98, 154,  12, 101, 126,  22, 102, 130,\n",
              "          3, 120,  84,  36, 143,  61,  12, 135,  69,  22, 145,  66,   8,\n",
              "        135,  56,  57, 108,  69,  53, 130, 174, 151,  76, 172,  63,  74,\n",
              "        170,  53, 110, 173,  42,  81, 169,  36, 117, 157,  36,  81, 171,\n",
              "         12,  92, 168,  22, 117, 156,  22, 116, 174,  12,  79, 174,  36,\n",
              "        141, 174,  22, 120, 174,  44, 167, 174,  44,  75, 174,  44,  63,\n",
              "        164,  49,  79, 155,  36,  73, 134,  36,  98, 158,  22, 130, 139,\n",
              "         57,  84, 126,  22,  91, 161,   3, 117, 146,   3, 110, 129,  22,\n",
              "        115,  84,  22,  95,  63,  49, 140,  67,  44, 120,  61,  22, 110,\n",
              "         69,  22,  98,  49,   8, 153, 166,  60,  92, 162,  35, 102, 147,\n",
              "         43, 110, 163,   3, 102, 120,  22, 110, 147,  10,  84, 159,  12,\n",
              "        108,  95,  22, 120,  95,   3, 126, 144,  12, 130,  53,  19,  84,\n",
              "         78,  59, 147,  92,  44, 102,  69,   2,  83,  67,  12], dtype=int32),\n",
              " 'split0_test_score': array([0.94736842, 0.92982456, 0.92982456, 0.94736842, 0.95614035,\n",
              "        0.97368421, 0.94736842, 0.92982456, 0.98245614, 0.94736842,\n",
              "        0.9122807 , 0.97368421, 0.94736842, 0.95614035, 0.96491228,\n",
              "        0.94736842, 0.95614035, 0.96491228, 0.94736842, 0.9122807 ,\n",
              "        0.97368421, 0.94736842, 0.92982456, 0.97368421, 0.94736842,\n",
              "        0.93859649, 0.98245614, 0.94736842, 0.94736842, 0.97368421,\n",
              "        0.94736842, 0.95614035, 0.98245614, 0.94736842, 0.96491228,\n",
              "        0.97368421, 0.94736842, 0.94736842, 0.97368421, 0.94736842,\n",
              "        0.95614035, 0.95614035, 0.94736842, 0.95614035, 0.98245614,\n",
              "        0.95614035, 0.62280702, 0.93859649, 0.96491228, 0.62280702,\n",
              "        0.96491228, 0.98245614, 0.89473684, 0.96491228, 0.95614035,\n",
              "        0.62280702, 0.96491228, 0.95614035, 0.84210526, 0.96491228,\n",
              "        0.93859649, 0.9122807 , 0.96491228, 0.94736842, 0.62280702,\n",
              "        0.98245614, 0.95614035, 0.85087719, 0.97368421, 0.94736842,\n",
              "        0.9122807 , 0.98245614, 0.95614035, 0.62280702, 0.97368421,\n",
              "        0.94736842, 0.62280702, 0.97368421, 0.95614035, 0.62280702,\n",
              "        0.97368421, 0.93859649, 0.62280702, 0.97368421, 0.64035088,\n",
              "        0.62280702, 0.97368421, 0.95614035, 0.62280702, 0.98245614,\n",
              "        0.95614035, 0.9122807 , 0.96491228, 0.95614035, 0.89473684,\n",
              "        0.97368421, 0.95614035, 0.92982456, 0.96491228, 0.94736842,\n",
              "        0.88596491, 0.97368421, 0.95614035, 0.92982456, 0.96491228,\n",
              "        0.95614035, 0.93859649, 0.97368421, 0.95614035, 0.92105263,\n",
              "        0.98245614, 0.95614035, 0.92982456, 0.98245614, 0.95614035,\n",
              "        0.93859649, 0.98245614, 0.94736842, 0.92982456, 0.97368421,\n",
              "        0.93859649, 0.94736842, 0.96491228, 0.93859649, 0.95614035,\n",
              "        0.96491228, 0.93859649, 0.96491228, 0.96491228, 0.94736842,\n",
              "        0.95614035, 0.98245614, 0.93859649, 0.95614035, 0.97368421,\n",
              "        0.95614035, 0.89473684, 0.96491228, 0.94736842, 0.9122807 ,\n",
              "        0.99122807, 0.94736842, 0.92982456, 0.96491228, 0.94736842,\n",
              "        0.9122807 , 0.98245614, 0.94736842, 0.93859649, 0.97368421,\n",
              "        0.95614035, 0.92982456, 0.97368421, 0.95614035, 0.90350877,\n",
              "        0.98245614, 0.94736842, 0.93859649, 0.98245614, 0.95614035,\n",
              "        0.92982456, 0.98245614, 0.95614035, 0.92982456, 0.98245614,\n",
              "        0.95614035, 0.94736842, 0.97368421, 0.95614035, 0.94736842,\n",
              "        0.98245614, 0.94736842, 0.94736842, 0.96491228, 0.94736842,\n",
              "        0.94736842, 0.97368421, 0.95614035, 0.95614035, 0.97368421]),\n",
              " 'split1_test_score': array([0.93859649, 0.9122807 , 0.94736842, 0.93859649, 0.94736842,\n",
              "        0.97368421, 0.93859649, 0.94736842, 0.97368421, 0.94736842,\n",
              "        0.92105263, 0.97368421, 0.94736842, 0.96491228, 0.97368421,\n",
              "        0.94736842, 0.93859649, 0.97368421, 0.94736842, 0.93859649,\n",
              "        0.97368421, 0.94736842, 0.94736842, 0.97368421, 0.94736842,\n",
              "        0.94736842, 0.97368421, 0.93859649, 0.94736842, 0.97368421,\n",
              "        0.93859649, 0.97368421, 0.97368421, 0.93859649, 0.96491228,\n",
              "        0.97368421, 0.93859649, 0.96491228, 0.97368421, 0.93859649,\n",
              "        0.96491228, 0.95614035, 0.94736842, 0.97368421, 0.95614035,\n",
              "        0.93859649, 0.62280702, 0.92105263, 0.96491228, 0.68421053,\n",
              "        0.96491228, 0.96491228, 0.62280702, 0.96491228, 0.97368421,\n",
              "        0.64035088, 0.95614035, 0.95614035, 0.62280702, 0.96491228,\n",
              "        0.95614035, 0.92982456, 0.96491228, 0.95614035, 0.65789474,\n",
              "        0.96491228, 0.97368421, 0.75438596, 0.96491228, 0.95614035,\n",
              "        0.92105263, 0.95614035, 0.97368421, 0.62280702, 0.96491228,\n",
              "        0.96491228, 0.62280702, 0.96491228, 0.96491228, 0.62280702,\n",
              "        0.96491228, 0.96491228, 0.62280702, 0.95614035, 0.95614035,\n",
              "        0.62280702, 0.96491228, 0.96491228, 0.62280702, 0.95614035,\n",
              "        0.96491228, 0.92105263, 0.96491228, 0.94736842, 0.92982456,\n",
              "        0.96491228, 0.97368421, 0.93859649, 0.96491228, 0.95614035,\n",
              "        0.93859649, 0.97368421, 0.96491228, 0.95614035, 0.96491228,\n",
              "        0.96491228, 0.93859649, 0.97368421, 0.95614035, 0.92105263,\n",
              "        0.97368421, 0.94736842, 0.92982456, 0.97368421, 0.96491228,\n",
              "        0.94736842, 0.96491228, 0.95614035, 0.97368421, 0.97368421,\n",
              "        0.96491228, 0.97368421, 0.97368421, 0.95614035, 0.95614035,\n",
              "        0.96491228, 0.96491228, 0.96491228, 0.97368421, 0.96491228,\n",
              "        0.96491228, 0.95614035, 0.94736842, 0.96491228, 0.97368421,\n",
              "        0.95614035, 0.9122807 , 0.96491228, 0.94736842, 0.92982456,\n",
              "        0.96491228, 0.93859649, 0.93859649, 0.96491228, 0.96491228,\n",
              "        0.9122807 , 0.97368421, 0.94736842, 0.95614035, 0.97368421,\n",
              "        0.96491228, 0.93859649, 0.97368421, 0.96491228, 0.93859649,\n",
              "        0.97368421, 0.96491228, 0.95614035, 0.96491228, 0.94736842,\n",
              "        0.95614035, 0.97368421, 0.95614035, 0.93859649, 0.96491228,\n",
              "        0.96491228, 0.96491228, 0.97368421, 0.95614035, 0.95614035,\n",
              "        0.94736842, 0.94736842, 0.95614035, 0.96491228, 0.94736842,\n",
              "        0.96491228, 0.97368421, 0.94736842, 0.95614035, 0.98245614]),\n",
              " 'split2_test_score': array([0.95614035, 0.95614035, 0.97368421, 0.95614035, 0.97368421,\n",
              "        0.97368421, 0.95614035, 0.96491228, 0.97368421, 0.94736842,\n",
              "        0.95614035, 0.97368421, 0.94736842, 0.97368421, 0.96491228,\n",
              "        0.94736842, 0.96491228, 0.97368421, 0.94736842, 0.96491228,\n",
              "        0.97368421, 0.95614035, 0.98245614, 0.97368421, 0.94736842,\n",
              "        0.98245614, 0.97368421, 0.95614035, 0.98245614, 0.96491228,\n",
              "        0.94736842, 0.99122807, 0.97368421, 0.94736842, 0.96491228,\n",
              "        0.96491228, 0.94736842, 0.99122807, 0.97368421, 0.94736842,\n",
              "        1.        , 0.97368421, 0.95614035, 0.96491228, 0.96491228,\n",
              "        0.96491228, 0.63157895, 0.97368421, 0.96491228, 0.63157895,\n",
              "        0.97368421, 0.95614035, 0.63157895, 0.97368421, 0.94736842,\n",
              "        0.64035088, 0.99122807, 0.95614035, 0.80701754, 0.97368421,\n",
              "        0.95614035, 0.94736842, 0.97368421, 0.96491228, 0.64912281,\n",
              "        0.97368421, 0.94736842, 0.81578947, 0.97368421, 0.93859649,\n",
              "        0.94736842, 0.97368421, 0.95614035, 0.63157895, 0.98245614,\n",
              "        0.97368421, 0.63157895, 0.96491228, 0.93859649, 0.63157895,\n",
              "        0.97368421, 0.95614035, 0.63157895, 0.96491228, 0.96491228,\n",
              "        0.63157895, 0.95614035, 0.96491228, 0.63157895, 0.95614035,\n",
              "        0.95614035, 0.93859649, 0.97368421, 0.96491228, 0.95614035,\n",
              "        0.97368421, 0.96491228, 0.98245614, 0.97368421, 0.93859649,\n",
              "        0.95614035, 0.97368421, 0.95614035, 0.97368421, 0.96491228,\n",
              "        0.95614035, 0.98245614, 0.96491228, 0.94736842, 0.96491228,\n",
              "        0.97368421, 0.93859649, 0.98245614, 0.97368421, 0.94736842,\n",
              "        0.98245614, 0.96491228, 0.96491228, 0.98245614, 0.96491228,\n",
              "        0.97368421, 0.98245614, 0.96491228, 0.96491228, 0.98245614,\n",
              "        0.96491228, 0.94736842, 0.99122807, 0.97368421, 0.95614035,\n",
              "        0.97368421, 0.97368421, 0.95614035, 0.98245614, 0.97368421,\n",
              "        0.96491228, 0.84210526, 0.97368421, 0.95614035, 0.96491228,\n",
              "        0.97368421, 0.95614035, 0.95614035, 0.96491228, 0.95614035,\n",
              "        0.94736842, 0.97368421, 0.95614035, 0.97368421, 0.97368421,\n",
              "        0.94736842, 0.98245614, 0.97368421, 0.94736842, 0.94736842,\n",
              "        0.97368421, 0.95614035, 0.98245614, 0.97368421, 0.95614035,\n",
              "        0.98245614, 0.97368421, 0.94736842, 0.96491228, 0.97368421,\n",
              "        0.94736842, 0.99122807, 0.96491228, 0.97368421, 0.97368421,\n",
              "        0.96491228, 0.94736842, 0.96491228, 0.96491228, 0.95614035,\n",
              "        0.98245614, 0.97368421, 0.95614035, 0.97368421, 0.96491228]),\n",
              " 'split3_test_score': array([0.96491228, 0.93859649, 0.97368421, 0.95614035, 0.96491228,\n",
              "        0.95614035, 0.97368421, 0.94736842, 0.97368421, 0.95614035,\n",
              "        0.94736842, 0.96491228, 0.97368421, 0.94736842, 0.96491228,\n",
              "        0.95614035, 0.93859649, 0.96491228, 0.95614035, 0.94736842,\n",
              "        0.97368421, 0.94736842, 0.95614035, 0.96491228, 0.96491228,\n",
              "        0.95614035, 0.97368421, 0.96491228, 0.96491228, 0.96491228,\n",
              "        0.96491228, 0.95614035, 0.96491228, 0.96491228, 0.96491228,\n",
              "        0.97368421, 0.94736842, 0.96491228, 0.98245614, 0.96491228,\n",
              "        0.96491228, 0.97368421, 0.96491228, 0.96491228, 0.97368421,\n",
              "        0.96491228, 0.63157895, 0.94736842, 0.95614035, 0.63157895,\n",
              "        0.95614035, 0.98245614, 0.63157895, 0.97368421, 0.94736842,\n",
              "        0.63157895, 0.97368421, 0.95614035, 0.86842105, 0.97368421,\n",
              "        0.94736842, 0.95614035, 0.97368421, 0.95614035, 0.64035088,\n",
              "        0.97368421, 0.94736842, 0.86842105, 0.97368421, 0.95614035,\n",
              "        0.95614035, 0.97368421, 0.95614035, 0.63157895, 0.97368421,\n",
              "        0.96491228, 0.63157895, 0.97368421, 0.97368421, 0.63157895,\n",
              "        0.97368421, 0.94736842, 0.63157895, 0.97368421, 0.95614035,\n",
              "        0.63157895, 0.97368421, 0.95614035, 0.63157895, 0.97368421,\n",
              "        0.98245614, 0.93859649, 0.96491228, 0.98245614, 0.95614035,\n",
              "        0.96491228, 0.97368421, 0.93859649, 0.97368421, 0.95614035,\n",
              "        0.95614035, 0.96491228, 0.94736842, 0.94736842, 0.96491228,\n",
              "        0.96491228, 0.95614035, 0.97368421, 0.95614035, 0.93859649,\n",
              "        0.97368421, 0.95614035, 0.94736842, 0.97368421, 0.95614035,\n",
              "        0.94736842, 0.97368421, 0.96491228, 0.95614035, 0.97368421,\n",
              "        0.95614035, 0.95614035, 0.96491228, 0.95614035, 0.95614035,\n",
              "        0.97368421, 0.95614035, 0.95614035, 0.97368421, 0.95614035,\n",
              "        0.96491228, 0.97368421, 0.95614035, 0.96491228, 0.98245614,\n",
              "        0.95614035, 0.93859649, 0.96491228, 0.97368421, 0.94736842,\n",
              "        0.96491228, 0.96491228, 0.97368421, 0.96491228, 0.95614035,\n",
              "        0.94736842, 0.97368421, 0.95614035, 0.93859649, 0.96491228,\n",
              "        0.95614035, 0.94736842, 0.96491228, 0.97368421, 0.94736842,\n",
              "        0.96491228, 0.94736842, 0.95614035, 0.96491228, 0.94736842,\n",
              "        0.96491228, 0.97368421, 0.95614035, 0.94736842, 0.97368421,\n",
              "        0.95614035, 0.97368421, 0.96491228, 0.95614035, 0.96491228,\n",
              "        0.96491228, 0.95614035, 0.95614035, 0.97368421, 0.95614035,\n",
              "        0.96491228, 0.97368421, 0.97368421, 0.96491228, 0.97368421]),\n",
              " 'split4_test_score': array([0.97345133, 0.92920354, 0.99115044, 0.97345133, 0.96460177,\n",
              "        1.        , 0.97345133, 0.95575221, 1.        , 0.97345133,\n",
              "        0.96460177, 1.        , 0.97345133, 0.96460177, 0.99115044,\n",
              "        0.95575221, 0.96460177, 1.        , 0.99115044, 0.96460177,\n",
              "        0.99115044, 0.99115044, 0.96460177, 0.99115044, 0.98230088,\n",
              "        0.95575221, 0.99115044, 0.97345133, 0.96460177, 0.99115044,\n",
              "        0.96460177, 0.97345133, 0.99115044, 0.97345133, 0.97345133,\n",
              "        0.99115044, 0.97345133, 0.97345133, 0.99115044, 0.97345133,\n",
              "        0.97345133, 0.99115044, 0.97345133, 0.97345133, 0.98230088,\n",
              "        0.95575221, 0.62831858, 0.96460177, 0.97345133, 0.62831858,\n",
              "        0.98230088, 0.94690265, 0.62831858, 0.98230088, 0.96460177,\n",
              "        0.63716814, 0.98230088, 0.98230088, 0.87610619, 0.99115044,\n",
              "        0.98230088, 0.96460177, 0.99115044, 0.98230088, 0.63716814,\n",
              "        0.99115044, 0.97345133, 0.90265487, 0.99115044, 0.98230088,\n",
              "        0.97345133, 0.99115044, 0.94690265, 0.62831858, 0.99115044,\n",
              "        0.96460177, 0.62831858, 0.99115044, 0.9380531 , 0.62831858,\n",
              "        0.99115044, 0.97345133, 0.62831858, 0.99115044, 0.97345133,\n",
              "        0.62831858, 0.99115044, 0.98230088, 0.62831858, 0.99115044,\n",
              "        0.98230088, 0.95575221, 0.99115044, 0.96460177, 0.98230088,\n",
              "        0.99115044, 0.96460177, 0.98230088, 0.99115044, 0.99115044,\n",
              "        0.96460177, 0.99115044, 0.95575221, 0.96460177, 0.99115044,\n",
              "        0.96460177, 0.96460177, 0.99115044, 0.98230088, 0.95575221,\n",
              "        0.99115044, 0.98230088, 0.96460177, 0.99115044, 0.96460177,\n",
              "        0.96460177, 0.99115044, 0.95575221, 0.96460177, 0.99115044,\n",
              "        0.96460177, 0.98230088, 0.99115044, 0.95575221, 0.98230088,\n",
              "        0.99115044, 0.97345133, 0.97345133, 0.99115044, 0.96460177,\n",
              "        0.97345133, 0.99115044, 0.99115044, 0.99115044, 0.99115044,\n",
              "        0.91150442, 0.92920354, 0.98230088, 0.97345133, 0.94690265,\n",
              "        0.98230088, 0.98230088, 0.95575221, 1.        , 0.96460177,\n",
              "        0.95575221, 0.99115044, 0.98230088, 0.97345133, 0.99115044,\n",
              "        0.96460177, 0.95575221, 1.        , 0.96460177, 0.96460177,\n",
              "        0.99115044, 0.97345133, 0.96460177, 0.99115044, 0.97345133,\n",
              "        0.96460177, 0.99115044, 0.96460177, 0.97345133, 0.99115044,\n",
              "        0.95575221, 0.98230088, 1.        , 0.96460177, 0.97345133,\n",
              "        0.99115044, 0.95575221, 0.97345133, 0.99115044, 0.98230088,\n",
              "        0.97345133, 1.        , 0.97345133, 0.98230088, 0.99115044]),\n",
              " 'std_fit_time': array([0.06012925, 0.00832923, 0.09730124, 0.13027751, 0.03601858,\n",
              "        0.13578335, 0.12477636, 0.05726531, 0.0705505 , 0.16503016,\n",
              "        0.01069268, 0.01924591, 0.35036396, 0.07984125, 0.11580361,\n",
              "        0.58263775, 0.0175261 , 0.10296565, 0.13264791, 0.0217208 ,\n",
              "        0.05947251, 0.10963246, 0.04934323, 0.06744273, 0.12257011,\n",
              "        0.0426253 , 0.10355227, 0.19801269, 0.00441055, 0.05117282,\n",
              "        0.43340678, 0.07867719, 0.06787058, 0.40303652, 0.10037793,\n",
              "        0.13464623, 0.49391783, 0.01677353, 0.10377794, 0.74404424,\n",
              "        0.1233487 , 0.09957554, 0.87727128, 0.13863027, 0.1074773 ,\n",
              "        0.01508612, 0.14387111, 0.0048701 , 0.02729775, 0.29310776,\n",
              "        0.03555811, 0.01037589, 0.64895124, 0.039461  , 0.06248253,\n",
              "        0.41887248, 0.01485821, 0.037203  , 0.86287914, 0.13264221,\n",
              "        0.04891714, 0.03286675, 0.13093679, 0.16622042, 0.03176523,\n",
              "        0.01628678, 0.14244302, 0.02830087, 0.24659781, 0.06633867,\n",
              "        0.01185221, 0.17329401, 0.12907262, 0.05426382, 0.01278104,\n",
              "        0.14921176, 0.07025624, 0.10523585, 0.14078324, 0.08167272,\n",
              "        0.18856137, 0.21504363, 0.02379925, 0.27744437, 0.55625701,\n",
              "        0.03018082, 0.41501274, 0.31629436, 0.03033892, 0.39191312,\n",
              "        0.01793121, 0.00675918, 0.00855223, 0.01777036, 0.0211486 ,\n",
              "        0.06956446, 0.01449431, 0.01937965, 0.10000595, 0.02716702,\n",
              "        0.01430379, 0.02634056, 0.01786023, 0.07866054, 0.08266617,\n",
              "        0.03094067, 0.10889564, 0.15392383, 0.05718903, 0.00872611,\n",
              "        0.18206623, 0.03533811, 0.0913529 , 0.18259089, 0.05718162,\n",
              "        0.08301371, 0.11181097, 0.22557076, 0.02091434, 0.16971025,\n",
              "        0.05668327, 0.06931408, 0.13050138, 0.07256759, 0.2118468 ,\n",
              "        0.12766226, 0.10807904, 0.02361946, 0.34514312, 0.08295412,\n",
              "        0.22848601, 0.12414077, 0.07102356, 0.22378307, 0.17880596,\n",
              "        0.02970005, 0.00563949, 0.00936965, 0.06011797, 0.02113164,\n",
              "        0.07336846, 0.01085807, 0.08001015, 0.09206145, 0.01626102,\n",
              "        0.02397551, 0.01227797, 0.04778446, 0.05305259, 0.08207599,\n",
              "        0.0130633 , 0.09706276, 0.13463113, 0.03619417, 0.01297312,\n",
              "        0.13663298, 0.02859306, 0.07308953, 0.11973599, 0.04895603,\n",
              "        0.077854  , 0.07247711, 0.05193395, 0.02086015, 0.2219111 ,\n",
              "        0.01503685, 0.26715391, 0.30220192, 0.06293016, 0.21982112,\n",
              "        0.37689833, 0.12505746, 0.02797503, 0.42250846, 0.11755593,\n",
              "        0.16978929, 0.27078541, 0.10756503, 0.13927172, 0.40374681]),\n",
              " 'std_score_time': array([1.89855492e-04, 6.22067655e-05, 3.72257134e-04, 1.99176508e-04,\n",
              "        5.14943068e-05, 8.62053733e-04, 2.52020956e-05, 1.62008188e-05,\n",
              "        8.42246693e-05, 2.61658932e-05, 1.69584680e-04, 4.44590304e-04,\n",
              "        2.13548528e-05, 8.43881340e-05, 2.15707554e-05, 1.06093857e-05,\n",
              "        1.50025732e-05, 5.18153294e-05, 3.54342951e-05, 1.82505484e-04,\n",
              "        2.67358134e-05, 4.38038196e-05, 3.96569729e-05, 9.29217221e-04,\n",
              "        2.54815817e-05, 2.41441635e-05, 7.13763906e-05, 3.12548480e-05,\n",
              "        1.21144795e-05, 5.22713582e-05, 3.08323806e-05, 5.65443205e-04,\n",
              "        1.05470516e-05, 7.34678099e-05, 1.05152551e-04, 5.60076452e-05,\n",
              "        3.77989630e-05, 2.48196375e-05, 1.36398767e-05, 1.52468963e-04,\n",
              "        2.83071840e-05, 2.82656261e-05, 4.47390161e-05, 2.22721240e-05,\n",
              "        1.44827903e-04, 2.22849681e-04, 2.10268946e-04, 3.86554682e-05,\n",
              "        7.97106587e-05, 1.83318717e-04, 1.91281572e-04, 2.93113341e-04,\n",
              "        2.23457543e-04, 1.65305076e-05, 2.01913371e-05, 2.49955473e-05,\n",
              "        4.53950718e-04, 1.56933766e-05, 2.17275601e-05, 4.44586662e-05,\n",
              "        7.72937296e-05, 9.22523283e-05, 2.74299513e-05, 2.60814670e-05,\n",
              "        1.20427582e-05, 6.28190926e-05, 3.06433826e-05, 1.23112669e-05,\n",
              "        9.55568578e-05, 2.36770528e-03, 4.44987441e-05, 5.54209103e-05,\n",
              "        4.37655992e-05, 2.20598908e-05, 3.21852719e-05, 2.00103508e-05,\n",
              "        8.99871440e-06, 2.94021829e-05, 1.66627127e-05, 8.08476804e-05,\n",
              "        7.47432169e-05, 2.99912757e-05, 9.04935423e-05, 2.93444363e-05,\n",
              "        5.91246158e-05, 3.85897687e-05, 3.97347577e-05, 2.80023205e-05,\n",
              "        6.35091604e-05, 4.33353497e-04, 2.16271510e-04, 4.21898770e-05,\n",
              "        3.21724600e-04, 4.37885043e-05, 2.45671280e-04, 1.39017455e-05,\n",
              "        3.35794266e-05, 5.41668962e-05, 2.89174906e-05, 2.47089083e-05,\n",
              "        1.95491395e-04, 1.51871969e-04, 1.60662283e-05, 1.22042370e-05,\n",
              "        4.45375606e-05, 4.95124616e-05, 4.58459524e-05, 1.66083142e-05,\n",
              "        3.10169285e-05, 1.73536143e-04, 1.82405016e-05, 3.92489193e-03,\n",
              "        2.12652266e-05, 2.41391718e-05, 3.06778662e-05, 3.56237889e-05,\n",
              "        1.54633519e-05, 2.17776286e-05, 2.21553169e-04, 2.66493533e-05,\n",
              "        2.06814341e-05, 3.46052392e-05, 5.79888489e-05, 1.74144168e-05,\n",
              "        7.37521429e-05, 2.05078787e-05, 1.95975570e-04, 1.89791468e-04,\n",
              "        6.15462866e-05, 6.01007037e-05, 9.55419612e-05, 2.23847495e-05,\n",
              "        3.72655485e-05, 3.49770375e-05, 4.20624974e-05, 1.66031891e-04,\n",
              "        1.33421082e-04, 1.85480424e-04, 5.50837943e-05, 2.42326261e-04,\n",
              "        1.07237656e-04, 2.14743020e-05, 1.33585911e-05, 4.83044749e-05,\n",
              "        2.04509226e-05, 3.32145748e-05, 3.75245698e-05, 2.92553350e-04,\n",
              "        3.21325981e-05, 2.69496955e-05, 2.97221440e-05, 4.16108115e-05,\n",
              "        1.53170902e-05, 1.40269575e-05, 8.77703472e-05, 1.40420245e-05,\n",
              "        1.82606843e-05, 2.97025536e-05, 3.41305502e-05, 8.53619225e-05,\n",
              "        3.74513016e-05, 6.44259059e-05, 1.25024120e-05, 2.19626868e-05,\n",
              "        5.33332503e-05, 6.82092846e-05, 3.86889814e-05, 1.78507861e-05,\n",
              "        1.50565816e-05, 2.19134561e-05, 2.89978159e-05, 4.25662572e-05,\n",
              "        4.83246642e-05, 1.05041999e-04, 2.35786211e-05, 5.71857983e-05,\n",
              "        6.26846653e-05, 2.19445620e-05, 1.93895146e-05, 1.28131743e-05]),\n",
              " 'std_test_score': array([0.01233969, 0.0142854 , 0.02175135, 0.01156016, 0.00892212,\n",
              "        0.01403509, 0.0139829 , 0.01159141, 0.01022974, 0.01014192,\n",
              "        0.02023362, 0.01189882, 0.01283522, 0.00892212, 0.01020046,\n",
              "        0.00420407, 0.01183521, 0.01289205, 0.01697898, 0.01947497,\n",
              "        0.00698649, 0.01697898, 0.01751322, 0.00856619, 0.01398078,\n",
              "        0.01467907, 0.00699039, 0.01233969, 0.0131126 , 0.00958083,\n",
              "        0.01045435, 0.0131165 , 0.00892131, 0.01282248, 0.00341562,\n",
              "        0.00856619, 0.01180958, 0.01423579, 0.00699039, 0.01282248,\n",
              "        0.01508667, 0.01310374, 0.01015802, 0.00651499, 0.01019793,\n",
              "        0.00961042, 0.00394868, 0.01867971, 0.00547451, 0.02248555,\n",
              "        0.00889701, 0.01416382, 0.10651464, 0.00651462, 0.01018781,\n",
              "        0.00664577, 0.01238356, 0.01046421, 0.09342257, 0.00958083,\n",
              "        0.0146226 , 0.01882062, 0.00958083, 0.01184392, 0.01180172,\n",
              "        0.00892131, 0.01184412, 0.05050787, 0.00856619, 0.0146226 ,\n",
              "        0.02253871, 0.01161624, 0.00871004, 0.00394868, 0.00892131,\n",
              "        0.00858291, 0.00394868, 0.00958083, 0.01415849, 0.00394868,\n",
              "        0.00856619, 0.01233969, 0.00394868, 0.01161155, 0.12908418,\n",
              "        0.00394868, 0.01161155, 0.00955251, 0.00394868, 0.01401376,\n",
              "        0.0118623 , 0.01517898, 0.01020046, 0.01162858, 0.029629  ,\n",
              "        0.00958083, 0.00658206, 0.02310433, 0.00958083, 0.01786237,\n",
              "        0.02845211, 0.00856619, 0.00555003, 0.01504893, 0.01049526,\n",
              "        0.00424816, 0.01661127, 0.00856619, 0.01183932, 0.01782333,\n",
              "        0.00699039, 0.0146226 , 0.02041721, 0.00699039, 0.00649877,\n",
              "        0.01565744, 0.0102058 , 0.00658686, 0.01805087, 0.00856619,\n",
              "        0.01187197, 0.01422222, 0.01020046, 0.00858025, 0.01285412,\n",
              "        0.01020046, 0.01233969, 0.01188545, 0.00856619, 0.00649877,\n",
              "        0.00651499, 0.01161624, 0.01786237, 0.01286883, 0.00699039,\n",
              "        0.01903716, 0.03410448, 0.00696327, 0.01184412, 0.01785569,\n",
              "        0.01020861, 0.01504131, 0.01526843, 0.01403509, 0.00649877,\n",
              "        0.01880927, 0.00699039, 0.01283291, 0.01563982, 0.00856619,\n",
              "        0.00649877, 0.01804054, 0.01189882, 0.00892212, 0.02023362,\n",
              "        0.00892131, 0.01015802, 0.01423029, 0.0102058 , 0.00952421,\n",
              "        0.01717083, 0.00699039, 0.00545019, 0.01620435, 0.00892131,\n",
              "        0.00555003, 0.01507025, 0.01289205, 0.00698753, 0.01018213,\n",
              "        0.01527303, 0.00420407, 0.00887276, 0.01020046, 0.01283291,\n",
              "        0.01160953, 0.01052632, 0.01047225, 0.01018189, 0.00892131])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    }
  ]
}